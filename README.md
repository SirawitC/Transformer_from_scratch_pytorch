# Transformer from scratch using Pytorch

## Table of Contents
- [Introduction](#Introduction)
- [Core Components](#Core-Components)
  - [Input Embedding](#Input-Embedding)
  - [Positional Encoding](#Positional-Encoding)
  - [Multi-Head Attention](#Multi-Head-Attention)
  - [FeedForward Block](#FeedForward-Block)
  - [Residual Connection](#Residual-Connection)
  - [Layer Normalization](#Layer-Normalization)
- [Transformer Model](#Transformer-Model)
  - [Encoder](#Encoder)
  - [Decoder](#Decoder)
- [Training Loop](#Training-Loop)
- [Inference](#Inference)

## Introduction

## Core Components

### Input Embedding

### Positional Encoding

### Multi-Head Attention

### FeedForward Block

### Residual Connection

### Layer Normalization

## Transformer Model

### Encoder

### Decoder

## Training Loop

## Inference